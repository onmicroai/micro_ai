#\micro_ai\docker-compose-debug.yml

services:
  db:
    container_name: db
    image: postgres
    # persist data beyond lifetime of container
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data/
    environment:
      - POSTGRES_DB=micro_ai
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    networks:
      - microaiNetwork
    healthcheck:
      test: pg_isready -d $${POSTGRES_DB} -U $${POSTGRES_USER}
      interval: 2s
      retries: 10
  redis:
    container_name: redis
    image: redis
    # persistent storage
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    networks:
      - microaiNetwork
    healthcheck:
      test: bash -c 'exec 6<>/dev/tcp/redis/6379'
      interval: 2s
      retries: 10
  web:
    container_name: web
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    command: sh -c "python manage.py migrate && python -Xfrozen_modules=off -m debugpy --wait-for-client --listen 0.0.0.0:5678 manage.py runserver 0.0.0.0:8000 --nothreading"
    volumes:
      - ./backend:/code
    ports:
      - "8000:8000"
      - "5678:5678"
    env_file:
      - ./.env
    restart: unless-stopped
    networks:
      - microaiNetwork
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: curl --fail http://localhost:8000/ || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s
  celery:
    container_name: celery
    build:
      context: ./backend
      dockerfile: Dockerfile.dev
    command: celery -A micro_ai worker -l INFO --beat --concurrency 2
    volumes:
      - ./backend:/code
    env_file:
      - ./.env
    networks:
      - microaiNetwork
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      web:
        condition: service_healthy
  frontend:
    container_name: frontend
    build:
      context: ./frontend
      dockerfile: Dockerfile
    expose:
      - "3000"
    volumes:
      - ./frontend:/frontend
      - /frontend/node_modules
    networks:
      - microaiNetwork
    env_file:
      - ./.env
    environment:
      - NODE_ENV=development
      - WATCHPACK_POLLING=true
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "3"
    healthcheck:
      test: ["CMD-SHELL", "node -e \"const http = require('http'); const options = { host: 'localhost', port: 3000, path: '/', timeout: 2000 }; const request = http.request(options, (res) => { process.exit(res.statusCode === 200 ? 0 : 1); }); request.on('error', () => process.exit(1)); request.end();\""]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 20s
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx/nginx.local.conf:/etc/nginx/conf.d/default.conf
    networks:
      - microaiNetwork
    depends_on:
      frontend:
        condition: service_healthy
      web:
        condition: service_healthy
      celery:
        condition: service_healthy

volumes:
  postgres_data:
  redis_data:

networks:
  microaiNetwork:
    driver: bridge